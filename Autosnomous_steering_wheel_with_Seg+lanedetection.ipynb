{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonseungho-glitch/Road_Lane_segmentation/blob/main/Autosnomous_steering_wheel_with_Seg%2Blanedetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì˜¤ë²„ë ˆì´ ë° ì‹œê°í™” ì›ë³¸ì´ë¯¸ì§€ ì£¼í–‰ì°¨ì„  ê·¸ë¦¬ê¸° -> Segì´ë¯¸ì§€ ì˜¤ë²„ë ˆì´"
      ],
      "metadata": {
        "id": "mf2UvTiJtqjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Final Integrated Code: Dual Input (PNG/JPG) + Stabilized Steering\n",
        "# Fixed: ValueError on Mutable Defaults\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install -U segmentation-models-pytorch timm natsort\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from natsort import natsorted\n",
        "import segmentation_models_pytorch as smp\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Optional, List\n",
        "\n",
        "# ==========================================\n",
        "# 1) Configuration (Centralized Control)\n",
        "# ==========================================\n",
        "@dataclass(frozen=True)\n",
        "class Config:\n",
        "    # --- Paths ---\n",
        "    CKPT_PATH: str      = \"/content/drive/MyDrive/DataSet/best.pt\"                       # Lane Detection Model\n",
        "    RAW_IMG_DIR: str    = \"/content/drive/MyDrive/DataSet/sample/inference_img\"          # Original Image Set\n",
        "    SEG_VIS_DIR: str    = \"/content/dataset/inference/sample_img\"                        # Segmentation Image Set\n",
        "    WHEEL_PATH: str     = \"/content/drive/MyDrive/DataSet/Yoke_Steering_wheel.png\"       # Steering Wheel Image\n",
        "    OUT_VIDEO_PATH: str = \"/content/drive/MyDrive/DataSet/Autonomous_Steering.mp4\"       # Out Video Path & Name\n",
        "\n",
        "    # --- Video & Model Settings ---\n",
        "    FPS: int            = 10\n",
        "    ENCODER_NAME: str   = \"resnet50\"\n",
        "    NUM_CLASSES: int    = 1\n",
        "    RESIZE_SHORTEST: int= 1024\n",
        "    RESIZE_LONGEST: int = 1920\n",
        "    SIZE_DIVISOR: int   = 32\n",
        "    THRESH: float       = 0.5\n",
        "\n",
        "    # --- Visualization ---\n",
        "    LANE_COLOR_BGR: Tuple[int, int, int] = (0, 255, 0)\n",
        "    LANE_ALPHA: float   = 0.45\n",
        "    SCAN_ALPHA: float   = 0.60\n",
        "    SCANLINE_COLOR: Tuple[int, int, int] = (255, 0, 0) # Blue\n",
        "\n",
        "    # --- Steering & Control Logic ---\n",
        "    SCAN_Y_RATIO: float         = 0.70  # Scanline height ratio\n",
        "    STEERING_SENSITIVITY: float = 3.0   # Multiplier\n",
        "    SMOOTHING: float            = 0.15  # Exponential Moving Average factor\n",
        "    POWER_FACTOR: float         = 1.4   # Non-linear response\n",
        "    DEADZONE: float             = 1.9   # Minimum angle to react\n",
        "    LANE_OFFSET_PIXELS: int     = 160   # Virtual lane center offset\n",
        "    MAX_ANGLE: float            = 90.0  # Physical limit\n",
        "\n",
        "    # --- System ---\n",
        "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # [FIX] Use Tuples instead of np.array to avoid ValueError in dataclass\n",
        "    # Numpy will automatically handle the math with these tuples.\n",
        "    MEAN: Tuple[float, float, float] = (0.485, 0.456, 0.406)\n",
        "    STD: Tuple[float, float, float]  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# ==========================================\n",
        "# 2) Image Processing Utilities\n",
        "# ==========================================\n",
        "class ImageUtils:\n",
        "    @staticmethod\n",
        "    def resize_keep_aspect(H: int, W: int, shortest: int, longest: int) -> Tuple[int, int]:\n",
        "        scale = shortest / min(H, W)\n",
        "        newH, newW = int(round(H * scale)), int(round(W * scale))\n",
        "        if max(newH, newW) > longest:\n",
        "            scale = longest / max(newH, newW)\n",
        "            newH, newW = int(round(newH * scale)), int(round(newW * scale))\n",
        "        return max(1, newH), max(1, newW)\n",
        "\n",
        "    @staticmethod\n",
        "    def pad_to_divisor_chw(x_chw: torch.Tensor, divisor=32, pad_value=0.0):\n",
        "        C, H, W = x_chw.shape\n",
        "        padH = (divisor - H % divisor) % divisor\n",
        "        padW = (divisor - W % divisor) % divisor\n",
        "        if padH == 0 and padW == 0:\n",
        "            return x_chw, (0, 0, 0, 0)\n",
        "        x_chw = F.pad(x_chw, (0, padW, 0, padH), value=float(pad_value))\n",
        "        return x_chw, (0, padW, 0, padH)\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(frame_bgr: np.ndarray) -> Tuple[torch.Tensor, Tuple[int, int], Tuple[int, int]]:\n",
        "        origH, origW = frame_bgr.shape[:2]\n",
        "        newH, newW = ImageUtils.resize_keep_aspect(origH, origW, Config.RESIZE_SHORTEST, Config.RESIZE_LONGEST)\n",
        "\n",
        "        rs = cv2.resize(frame_bgr, (newW, newH), interpolation=cv2.INTER_LINEAR)\n",
        "        rgb = cv2.cvtColor(rs, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "\n",
        "        # [NOTE] Numpy broadcasts tuples (Config.MEAN) against arrays automatically\n",
        "        rgb = (rgb - Config.MEAN) / Config.STD\n",
        "\n",
        "        x = torch.from_numpy(rgb).permute(2, 0, 1).float()\n",
        "        x, _ = ImageUtils.pad_to_divisor_chw(x, divisor=Config.SIZE_DIVISOR, pad_value=0.0)\n",
        "        x = x.unsqueeze(0)\n",
        "        return x, (origH, origW), (newH, newW)\n",
        "\n",
        "# ==========================================\n",
        "# 3) Lane Pilot Class (Logic & Visualization)\n",
        "# ==========================================\n",
        "class LanePilot:\n",
        "    def __init__(self):\n",
        "        self.model = self._load_model()\n",
        "        self.prev_angle = 0.0\n",
        "        self.wheel_img = self._load_wheel()\n",
        "\n",
        "        # Performance settings\n",
        "        cv2.setNumThreads(0)\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        try:\n",
        "            torch.set_float32_matmul_precision(\"high\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def _load_model(self):\n",
        "        print(f\"[Init] Loading model from {Config.CKPT_PATH}...\")\n",
        "        ckpt = torch.load(Config.CKPT_PATH, map_location=\"cpu\")\n",
        "        sd = ckpt[\"model_state\"] if isinstance(ckpt, dict) and \"model_state\" in ckpt else ckpt\n",
        "\n",
        "        # Key normalization\n",
        "        clean_sd = {}\n",
        "        for k, v in sd.items():\n",
        "            for p in [\"module.\", \"model.\", \"_orig_mod.\", \"orig_mod.\"]:\n",
        "                if k.startswith(p): k = k[len(p):]\n",
        "            k = k.replace(\"module._orig_mod.\", \"\").replace(\"model._orig_mod.\", \"\")\n",
        "            clean_sd[k] = v\n",
        "\n",
        "        model = smp.DeepLabV3Plus(\n",
        "            encoder_name=Config.ENCODER_NAME,\n",
        "            encoder_weights=None,\n",
        "            in_channels=3,\n",
        "            classes=Config.NUM_CLASSES,\n",
        "            activation=None,\n",
        "        )\n",
        "        model.load_state_dict(clean_sd, strict=False)\n",
        "        model.to(Config.DEVICE).eval()\n",
        "        return model\n",
        "\n",
        "    def _load_wheel(self):\n",
        "        if not os.path.exists(Config.WHEEL_PATH):\n",
        "            raise FileNotFoundError(f\"Wheel image not found at {Config.WHEEL_PATH}\")\n",
        "        return cv2.imread(Config.WHEEL_PATH, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def infer_mask(self, frame_bgr: np.ndarray) -> np.ndarray:\n",
        "        x, (origH, origW), (newH, newW) = ImageUtils.preprocess(frame_bgr)\n",
        "        x = x.to(Config.DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16, enabled=(Config.DEVICE == \"cuda\")):\n",
        "            logits = self.model(x)\n",
        "\n",
        "        if isinstance(logits, (list, tuple)): logits = logits[0]\n",
        "        if isinstance(logits, dict): logits = logits.get(\"logits\", logits.get(\"out\"))\n",
        "\n",
        "        logits = logits[:, :, :newH, :newW]\n",
        "        logits_up = F.interpolate(logits, size=(origH, origW), mode=\"bilinear\", align_corners=False)\n",
        "        prob = torch.sigmoid(logits_up)[0, 0].detach().cpu().numpy()\n",
        "        return (prob >= Config.THRESH).astype(np.uint8)\n",
        "\n",
        "    def calculate_steering(self, mask_pred: np.ndarray) -> Tuple[float, int, int]:\n",
        "        h, w = mask_pred.shape\n",
        "        img_center = w // 2\n",
        "        scan_y = int(h * Config.SCAN_Y_RATIO)\n",
        "\n",
        "        x_indices = np.where(mask_pred[scan_y, :] > 0)[0]\n",
        "\n",
        "        if len(x_indices) == 0:\n",
        "            return 0.0, img_center, scan_y\n",
        "\n",
        "        left_indices = x_indices[x_indices < img_center]\n",
        "        right_indices = x_indices[x_indices >= img_center]\n",
        "\n",
        "        l_inner = np.max(left_indices) if len(left_indices) > 0 else None\n",
        "        r_inner = np.min(right_indices) if len(right_indices) > 0 else None\n",
        "\n",
        "        if l_inner is not None and r_inner is not None:\n",
        "            lane_center = (l_inner + r_inner) // 2\n",
        "        elif l_inner is not None:\n",
        "            lane_center = l_inner + Config.LANE_OFFSET_PIXELS\n",
        "        elif r_inner is not None:\n",
        "            lane_center = r_inner - Config.LANE_OFFSET_PIXELS\n",
        "        else:\n",
        "            return 0.0, img_center, scan_y # Lane lost\n",
        "\n",
        "        # --- Control Logic ---\n",
        "        offset = lane_center - img_center\n",
        "        normalized_offset = offset / (w / 2) # -1.0 to 1.0\n",
        "\n",
        "        # Non-linear steering response\n",
        "        angle = np.sign(offset) * (abs(normalized_offset) ** Config.POWER_FACTOR) * 90 * Config.STEERING_SENSITIVITY\n",
        "\n",
        "        # Deadzone\n",
        "        if abs(angle) < Config.DEADZONE:\n",
        "            angle = 0.0\n",
        "\n",
        "        angle = np.clip(angle, -Config.MAX_ANGLE, Config.MAX_ANGLE)\n",
        "        return angle, int(lane_center), scan_y\n",
        "\n",
        "    def get_smoothed_angle(self, target_angle: float) -> float:\n",
        "        self.prev_angle = self.prev_angle * (1 - Config.SMOOTHING) + target_angle * Config.SMOOTHING\n",
        "        return self.prev_angle\n",
        "\n",
        "    def draw_overlays(self, frame: np.ndarray, mask: np.ndarray, angle: float) -> np.ndarray:\n",
        "        final_frame = frame.copy()\n",
        "\n",
        "        # 1. Ego-Lane Scanline Visualization\n",
        "        ego_line = self._draw_scanline(final_frame.shape, mask)\n",
        "        final_frame = cv2.addWeighted(final_frame, 1.0, ego_line, Config.SCAN_ALPHA, 0)\n",
        "\n",
        "        # 2. Green Lane Overlay\n",
        "        if mask.any():\n",
        "            color_mask = np.zeros_like(final_frame, dtype=np.uint8)\n",
        "            color_mask[mask > 0] = Config.LANE_COLOR_BGR\n",
        "            mask_bool = mask > 0\n",
        "            final_frame[mask_bool] = (\n",
        "                final_frame[mask_bool].astype(np.float32) * (1 - Config.LANE_ALPHA) +\n",
        "                color_mask[mask_bool].astype(np.float32) * Config.LANE_ALPHA\n",
        "            ).astype(np.uint8)\n",
        "\n",
        "        # 3. Steering Wheel\n",
        "        final_frame = self._draw_steering_wheel(final_frame, angle)\n",
        "\n",
        "        # 4. Text Info\n",
        "        cv2.putText(final_frame, f\"Angle: {angle:.1f}\", (30, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "        return final_frame\n",
        "\n",
        "    def _draw_scanline(self, img_shape: Tuple, mask_pred: np.ndarray) -> np.ndarray:\n",
        "        h, w = img_shape[:2]\n",
        "        overlay = np.zeros(img_shape, dtype=np.uint8)\n",
        "        bin_mask = (mask_pred > 0).astype(np.uint8)\n",
        "\n",
        "        start_y = int(h * 0.45)\n",
        "        prev_center = w * 0.5\n",
        "        prev_width = None\n",
        "\n",
        "        # Note: Vectorizing this specific tracking logic is complex due to the `prev_center` dependency.\n",
        "        # Keeping loop for correctness as requested, but optimized variable access.\n",
        "        for y in range(h - 1, start_y, -1):\n",
        "            row_pixels = bin_mask[y, :]\n",
        "            if not np.any(row_pixels): continue\n",
        "\n",
        "            xs = np.where(row_pixels)[0]\n",
        "\n",
        "            # Use prev_center to find closest lane boundaries\n",
        "            l_cands = xs[xs < prev_center]\n",
        "            r_cands = xs[xs >= prev_center]\n",
        "\n",
        "            xl = l_cands.max() if l_cands.size > 0 else None\n",
        "            xr = r_cands.min() if r_cands.size > 0 else None\n",
        "\n",
        "            draw_l, draw_r = None, None\n",
        "\n",
        "            if xl is not None and xr is not None and xl < xr:\n",
        "                wd = xr - xl\n",
        "                if 10 < wd < w * 0.9:\n",
        "                    draw_l, draw_r = xl, xr\n",
        "                    prev_width = wd\n",
        "                    prev_center = (xl + xr) / 2\n",
        "            elif prev_width is not None:\n",
        "                if xl is not None:\n",
        "                    draw_l = xl\n",
        "                    draw_r = int(xl + prev_width)\n",
        "                    prev_center = (draw_l + draw_r) / 2\n",
        "                elif xr is not None:\n",
        "                    draw_r = xr\n",
        "                    draw_l = int(xr - prev_width)\n",
        "                    prev_center = (draw_l + draw_r) / 2\n",
        "\n",
        "            if draw_l is not None and draw_r is not None:\n",
        "                # Optimized drawing: simple array slicing is faster than line drawing for horizontal lines\n",
        "                draw_l = max(0, min(draw_l, w-1))\n",
        "                draw_r = max(0, min(draw_r, w-1))\n",
        "                overlay[y, int(draw_l):int(draw_r)] = Config.SCANLINE_COLOR\n",
        "\n",
        "        return overlay\n",
        "\n",
        "    def _draw_steering_wheel(self, frame: np.ndarray, angle: float) -> np.ndarray:\n",
        "        rows, cols = frame.shape[:2]\n",
        "        wh, ww = self.wheel_img.shape[:2]\n",
        "\n",
        "        M = cv2.getRotationMatrix2D((ww // 2, wh // 2), -angle, 1.0)\n",
        "        rotated = cv2.warpAffine(self.wheel_img, M, (ww, wh),\n",
        "                                 flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_TRANSPARENT)\n",
        "\n",
        "        target_size = 300\n",
        "        rotated = cv2.resize(rotated, (target_size, target_size))\n",
        "        r_h, r_w = rotated.shape[:2]\n",
        "\n",
        "        x_off = (cols - r_w) // 2\n",
        "        y_off = rows - r_h - 20\n",
        "\n",
        "        roi = frame[y_off:y_off+r_h, x_off:x_off+r_w]\n",
        "\n",
        "        if rotated.shape[2] == 4:\n",
        "            b, g, r, a = cv2.split(rotated)\n",
        "            mask = (a.astype(np.float32) / 255.0)[..., None]\n",
        "            roi[:] = (mask * cv2.merge((b, g, r)) + (1 - mask) * roi.astype(np.float32)).astype(np.uint8)\n",
        "        else:\n",
        "            roi[:] = rotated\n",
        "\n",
        "        frame[y_off:y_off+r_h, x_off:x_off+r_w] = roi\n",
        "        return frame\n",
        "\n",
        "# ==========================================\n",
        "# 4) Main Execution\n",
        "# ==========================================\n",
        "def main():\n",
        "    # File Discovery\n",
        "    raw_files = natsorted(glob.glob(os.path.join(Config.RAW_IMG_DIR, \"*.jpg\")))\n",
        "    seg_files = natsorted(glob.glob(os.path.join(Config.SEG_VIS_DIR, \"*.png\")))\n",
        "\n",
        "    if not seg_files:\n",
        "        seg_files = natsorted(glob.glob(os.path.join(Config.SEG_VIS_DIR, \"*.jpg\")))\n",
        "\n",
        "    if not raw_files: raise FileNotFoundError(f\"No raw images in {Config.RAW_IMG_DIR}\")\n",
        "    if not seg_files: raise FileNotFoundError(f\"No seg images in {Config.SEG_VIS_DIR}\")\n",
        "\n",
        "    min_len = min(len(raw_files), len(seg_files))\n",
        "    print(f\"[Info] Found {len(raw_files)} raw, {len(seg_files)} seg -> Processing {min_len} frames.\")\n",
        "\n",
        "    # Prepare Output\n",
        "    os.makedirs(os.path.dirname(Config.OUT_VIDEO_PATH), exist_ok=True)\n",
        "    first_frame = cv2.imread(raw_files[0])\n",
        "    h, w = first_frame.shape[:2]\n",
        "\n",
        "    writer = cv2.VideoWriter(Config.OUT_VIDEO_PATH, cv2.VideoWriter_fourcc(*\"mp4v\"), Config.FPS, (w, h))\n",
        "\n",
        "    # Initialize Pilot\n",
        "    pilot = LanePilot()\n",
        "    print(f\"ðŸŽ¬ Processing started -> {Config.OUT_VIDEO_PATH}\")\n",
        "\n",
        "    # Process Loop\n",
        "    for i, (r_path, s_path) in enumerate(zip(raw_files[:min_len], seg_files[:min_len]), 1):\n",
        "\n",
        "        raw_frame = cv2.imread(r_path)\n",
        "        seg_vis_frame = cv2.imread(s_path)\n",
        "\n",
        "        if raw_frame is None or seg_vis_frame is None: continue\n",
        "\n",
        "        # Resize viz frame if needed\n",
        "        if seg_vis_frame.shape[:2] != (h, w):\n",
        "            seg_vis_frame = cv2.resize(seg_vis_frame, (w, h))\n",
        "\n",
        "        # 1. Inference\n",
        "        mask = pilot.infer_mask(raw_frame)\n",
        "\n",
        "        # 2. Control\n",
        "        target_angle, _, _ = pilot.calculate_steering(mask)\n",
        "        smooth_angle = pilot.get_smoothed_angle(target_angle)\n",
        "\n",
        "        # 3. Visualize\n",
        "        final_frame = pilot.draw_overlays(seg_vis_frame, mask, smooth_angle)\n",
        "\n",
        "        writer.write(final_frame)\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Progress: {i}/{min_len} frames | Angle: {smooth_angle:.2f}Â°\", end='\\r')\n",
        "\n",
        "    writer.release()\n",
        "    print(f\"\\nâœ… Done! Saved to: {Config.OUT_VIDEO_PATH}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "uN9LxM2IuQ2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738001c0-09c0-4426-d1a7-8b00840decb0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Found 246 raw, 246 seg -> Processing 246 frames.\n",
            "[Init] Loading model from /content/drive/MyDrive/DataSet/best.pt...\n",
            "ðŸŽ¬ Processing started -> /content/drive/MyDrive/DataSet/Autonomous_Steering.mp4\n",
            "\n",
            "âœ… Done! Saved to: /content/drive/MyDrive/DataSet/Autonomous_Steering.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDveNHJTh5TN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}